{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UNcFQ5xnDAx9V9l9mJPnY0EH2urRHmSF",
      "authorship_tag": "ABX9TyOWjUtEHahLGZnN/tUpQeEz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rociavl/SEEG_automatic_segmentation/blob/main/3D_filters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3D Filters\n"
      ],
      "metadata": {
        "id": "E88kDUUBvvfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HCgnqeyMEk1",
        "outputId": "a22fbc37-0f25-4a25-9a83-ae51040fdbdf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/MyDrive/TFG 💪🧠/Code/DATA/'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UFeFdfUMdW5",
        "outputId": "3d2a71be-bbff-497e-eb2c-0fe9d59d60f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P1  P2\tP3  P4\tP5  P6\tP7  P8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJg6Kz0hvm_i",
        "outputId": "97b24ef7-6181-4c83-9796-f4cd72b357e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.4.1\n",
            "Collecting pynrrd\n",
            "  Downloading pynrrd-1.1.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from pynrrd) (1.26.4)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from pynrrd) (4.12.2)\n",
            "Downloading pynrrd-1.1.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pynrrd\n",
            "Successfully installed pynrrd-1.1.3\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pynrrd\n",
        "!pip install scikit-image\n",
        "!pip install scipy\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.ndimage as ndi\n",
        "import SimpleITK as sitk  # For handling NRRD files\n",
        "from scipy.ndimage import gaussian_filter, median_filter, laplace, sobel\n",
        "import logging\n",
        "from skimage.filters import frangi\n",
        "from pathlib import Path\n",
        "import os\n",
        "from skimage.measure import regionprops\n",
        "import logging\n",
        "import nrrd\n",
        "from skimage.measure import label, regionprops\n",
        "from scipy.ndimage import gaussian_filter, median_filter, sobel\n",
        "from pathlib import Path\n",
        "import os\n",
        "from skimage.measure import label, regionprops\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import pandas as pd\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n"
      ],
      "metadata": {
        "id": "30i8daXAvzJe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read NRRD file\n",
        "def read_nrrd_file(file_path):\n",
        "    \"\"\"Reads an NRRD file and returns the image as a numpy array and SimpleITK image.\"\"\"\n",
        "    try:\n",
        "        image = sitk.ReadImage(file_path)\n",
        "        image_array = sitk.GetArrayFromImage(image)  # Convert to numpy array\n",
        "        print(f\"✅ Successfully read NRRD file: {file_path}\")\n",
        "        return image_array, image\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ Error reading NRRD file: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "# Save NRRD file\n",
        "def save_nrrd_file(image_array, image, output_file):\n",
        "    \"\"\"Saves a processed volume as an NRRD file using SimpleITK.\"\"\"\n",
        "    try:\n",
        "        output_image = sitk.GetImageFromArray(image_array)\n",
        "        output_image.SetSpacing(image.GetSpacing())\n",
        "        output_image.SetOrigin(image.GetOrigin())\n",
        "        sitk.WriteImage(output_image, output_file)\n",
        "        print(f\"✅ Saved NRRD file to {output_file}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ Error saving NRRD file: {str(e)}\")"
      ],
      "metadata": {
        "id": "_WJR-V31xRTn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_large_objects(volume, size_threshold):\n",
        "    \"\"\"\n",
        "    Removes objects that are larger than a given size threshold.\n",
        "\n",
        "    Parameters:\n",
        "        volume (numpy.ndarray): The 3D image (volume).\n",
        "        size_threshold (int): The size threshold for removing large objects.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The volume with large objects removed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Label connected components\n",
        "        labeled_volume, num_features = label(volume > 0)  # Only keep foreground\n",
        "\n",
        "        # Get the properties of the labeled regions\n",
        "        regions = regionprops(labeled_volume)\n",
        "\n",
        "        # Create an empty volume to hold the filtered results\n",
        "        filtered_volume = np.zeros_like(volume)\n",
        "\n",
        "        # Loop through the regions and keep only those below the size threshold\n",
        "        for region in regions:\n",
        "            if region.area <= size_threshold:\n",
        "                for coord in region.coords:\n",
        "                    filtered_volume[tuple(coord)] = volume[tuple(coord)]  # Keep small objects\n",
        "\n",
        "        print(f\"✅ Removed {num_features - len([r for r in regions if r.area <= size_threshold])} large objects\")\n",
        "        return filtered_volume\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ Error removing large objects: {str(e)}\")\n",
        "        return volume\n",
        "\n",
        "\n",
        "# Vesselness Filter (Custom Implementation)\n",
        "def vesselness_filter(image, sigma=1.0, alpha=0.5, beta=0.5):\n",
        "    \"\"\"\n",
        "    Applies custom vesselness filter for enhancing vessels.\n",
        "\n",
        "    Parameters:\n",
        "        image (numpy.ndarray): The 3D image (volume) to be filtered.\n",
        "        sigma (float): The standard deviation of the Gaussian filter used in Hessian computation.\n",
        "        alpha (float): The sensitivity parameter for vesselness calculation.\n",
        "        beta (float): The sensitivity parameter for vesselness calculation.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The vesselness-enhanced image.\n",
        "    \"\"\"\n",
        "    print(f\"Applying vesselness filter with sigma={sigma}, alpha={alpha}, beta={beta}\")\n",
        "    try:\n",
        "        # Compute Hessian manually\n",
        "        hessian_image = np.array([gaussian_filter(image, sigma=sigma, order=(2, 0, 0)),\n",
        "                                  gaussian_filter(image, sigma=sigma, order=(0, 2, 0)),\n",
        "                                  gaussian_filter(image, sigma=sigma, order=(0, 0, 2))])\n",
        "\n",
        "        # Compute eigenvalues of the Hessian matrix\n",
        "        eigvals = np.linalg.eigvalsh(hessian_image)\n",
        "\n",
        "        # Sort eigenvalues by absolute value\n",
        "        eigvals = np.sort(np.abs(eigvals), axis=0)\n",
        "\n",
        "        # Compute vesselness measure\n",
        "        vesselness = np.zeros_like(image)\n",
        "        lambda1, lambda2, lambda3 = eigvals[0], eigvals[1], eigvals[2]\n",
        "        vesselness = (1 - np.exp(-lambda2**2 / (2 * alpha**2))) * np.exp(-lambda3**2 / (2 * beta**2))\n",
        "\n",
        "        # Normalize vesselness\n",
        "        vesselness = (vesselness - vesselness.min()) / (vesselness.max() - vesselness.min())\n",
        "\n",
        "        return vesselness\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error applying vesselness filter: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Sobel filter for edge detection (CPU)\n",
        "def sobel_filter(image):\n",
        "    \"\"\"Applies Sobel edge detection filter on the CPU.\"\"\"\n",
        "    print(\"Applying Sobel edge detection filter\")\n",
        "    try:\n",
        "        edges = np.sqrt(sobel(image, axis=0)**2 + sobel(image, axis=1)**2 + sobel(image, axis=2)**2)\n",
        "        return edges\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error applying Sobel filter: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Gamma correction (CPU)\n",
        "def gamma_correction(image, gamma=1.0):\n",
        "    \"\"\"Applies Gamma correction to the image.\"\"\"\n",
        "    print(f\"Applying Gamma correction with gamma={gamma}\")\n",
        "    try:\n",
        "        image = np.power(image, gamma)\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error applying gamma correction: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def hessian_filter(image, sigma=1.0):\n",
        "    \"\"\"Apply Hessian-based filtering for blob detection.\"\"\"\n",
        "    # Compute the Hessian matrix at each voxel\n",
        "    grad_xx = gaussian_filter(image, sigma=sigma, order=(2, 0, 0))\n",
        "    grad_yy = gaussian_filter(image, sigma=sigma, order=(0, 2, 0))\n",
        "    grad_zz = gaussian_filter(image, sigma=sigma, order=(0, 0, 2))\n",
        "    grad_xy = gaussian_filter(image, sigma=sigma, order=(1, 1, 0))\n",
        "    grad_xz = gaussian_filter(image, sigma=sigma, order=(1, 0, 1))\n",
        "    grad_yz = gaussian_filter(image, sigma=sigma, order=(0, 1, 1))\n",
        "\n",
        "    # Construct the Hessian matrix\n",
        "    hessian = np.array([[[grad_xx, grad_xy, grad_xz],\n",
        "                         [grad_xy, grad_yy, grad_yz],\n",
        "                         [grad_xz, grad_yz, grad_zz]]])\n",
        "\n",
        "    # Use eigenvalues of the Hessian matrix for blob detection\n",
        "    eigenvalues = np.linalg.eigvals(hessian)\n",
        "    return eigenvalues\n",
        "\n",
        "def frangi_filter(image, sigma=1.0, beta=0.5):\n",
        "    \"\"\"Apply Frangi filter for enhancing tubular structures.\"\"\"\n",
        "    # Compute Hessian\n",
        "    grad_xx = gaussian_filter(image, sigma=sigma, order=(2, 0, 0))\n",
        "    grad_yy = gaussian_filter(image, sigma=sigma, order=(0, 2, 0))\n",
        "    grad_zz = gaussian_filter(image, sigma=sigma, order=(0, 0, 2))\n",
        "\n",
        "    # Compute the eigenvalues\n",
        "    eigvals = np.linalg.eigvals(np.array([[[grad_xx, grad_yy, grad_zz]]]))\n",
        "\n",
        "    # Compute the vesselness score\n",
        "    vesselness = np.exp(-eigvals[1] ** 2 / (2 * beta ** 2)) * np.exp(-eigvals[2] ** 2 / (2 * beta ** 2))\n",
        "\n",
        "    return vesselness\n",
        "\n",
        "def anisotropic_diffusion(image, num_iter=10, kappa=50, gamma=0.1):\n",
        "    \"\"\"Apply Anisotropic Diffusion (Perona-Malik) on a 3D image.\"\"\"\n",
        "    image = np.asarray(image)\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        # Calculate gradients\n",
        "        gradient_x = np.diff(image, axis=0, append=image[-1:])\n",
        "        gradient_y = np.diff(image, axis=1, append=image[-1:])\n",
        "        gradient_z = np.diff(image, axis=2, append=image[-1:])\n",
        "\n",
        "        # Compute the conductance (edge-preserving term)\n",
        "        c_x = np.exp(-(gradient_x / kappa) ** 2)\n",
        "        c_y = np.exp(-(gradient_y / kappa) ** 2)\n",
        "        c_z = np.exp(-(gradient_z / kappa) ** 2)\n",
        "\n",
        "        # Update the image using the conductance values\n",
        "        image[1:, :, :] += gamma * c_x[1:, :, :] * (image[:-1, :, :] - image[1:, :, :])\n",
        "        image[:, 1:, :] += gamma * c_y[:, 1:, :] * (image[:, :-1, :] - image[:, 1:, :])\n",
        "        image[:, :, 1:] += gamma * c_z[:, :, 1:] * (image[:, :, :-1] - image[:, :, 1:])\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "4xEASN5GIidu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply 3D filter method (CPU)\n",
        "def apply_3d_filter(volume, method, params=None):\n",
        "    \"\"\"Applies various 3D filters using CPU-based methods.\"\"\"\n",
        "    if params is None:\n",
        "        params = {}\n",
        "\n",
        "    try:\n",
        "        print(f\"Applying {method} filter with params: {params}\")\n",
        "\n",
        "        # Apply filters using NumPy (CPU-based)\n",
        "        if method == 'gaussian':\n",
        "            sigma = params.get('sigma', 1.5)\n",
        "            result = gaussian_filter(volume, sigma=sigma)\n",
        "        elif method == 'median':\n",
        "            size = params.get('size', 1)\n",
        "            result = median_filter(volume, size=size)\n",
        "        elif method == 'laplacian':\n",
        "            result = np.gradient(volume)  # A simple approach to Laplacian\n",
        "        elif method == 'vesselness':\n",
        "            result = vesselness_filter(volume, sigma=params.get('sigma', 1.0), alpha=params.get('alpha', 0.5), beta=params.get('beta', 0.5))\n",
        "        elif method == 'sobel':\n",
        "            result = sobel_filter(volume)\n",
        "        elif method == 'gamma_correction':\n",
        "            result = gamma_correction(volume, gamma=params.get('gamma', 1.0))\n",
        "        else:\n",
        "            logging.error(f\"Unknown filter method: {method}\")\n",
        "            return None\n",
        "\n",
        "        # Normalize output\n",
        "        result = (result - result.min()) / (result.max() - result.min())\n",
        "        print(f\"{method} filter applied and normalized successfully\")\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error applying {method} filter: {str(e)}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "W7srnLUENxLl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process volume with cascading filters using CPU"
      ],
      "metadata": {
        "id": "1wctH5k_In0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_volume_3d(input_volume_path, output_dir=None, methods=None):\n",
        "    \"\"\"Processes the volume with multiple filters in sequence.\"\"\"\n",
        "    try:\n",
        "        # Load the input volume\n",
        "        image_array, image = read_nrrd_file(input_volume_path)\n",
        "\n",
        "        if image_array is None or image is None:\n",
        "            print(\"❌ Failed to load input volume.\")\n",
        "            return\n",
        "\n",
        "        # Apply filters in sequence\n",
        "        enhanced_volumes = {}\n",
        "        for method, params in methods:\n",
        "            print(f\"Processing method: {method}\")\n",
        "            enhanced_image = apply_3d_filter(image_array, method, params)\n",
        "\n",
        "            if enhanced_image is None:\n",
        "                print(f\"❌ Skipping method {method} due to error.\")\n",
        "                continue\n",
        "\n",
        "            enhanced_volumes[method] = enhanced_image\n",
        "\n",
        "            # Save the enhanced volume as an NRRD file\n",
        "            if output_dir:\n",
        "                output_path = Path(output_dir)\n",
        "                output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                # Construct the output file path\n",
        "                output_file = output_path / f\"Enhanced_{method}_{os.path.basename(input_volume_path)}.nrrd\"\n",
        "                save_nrrd_file(enhanced_image, image, str(output_file))\n",
        "\n",
        "        return enhanced_volumes\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during volume processing: {str(e)}\")"
      ],
      "metadata": {
        "id": "9Piy2saav4SE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/TFG 💪🧠/Code/DATA/P1/P1/Enhance_ctp_3D'\n",
        "output_path = Path(output_dir)\n",
        "output_path.mkdir(parents=True, exist_ok=True)  # Ensure directory is created\n",
        "if output_path.exists():\n",
        "    print(f\"✅ Output directory exists or was created: {output_dir}\")\n",
        "else:\n",
        "    print(f\"❌ Failed to create output directory: {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33t0faAHJ87e",
        "outputId": "9c7c6f06-5324-46f2-f6fe-9aab5b663431"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Output directory exists or was created: /content/drive/MyDrive/TFG 💪🧠/Code/DATA/P1/P1/Enhance_ctp_3D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "input_volume_path ='/content/Filtered_og_ctp.3D.nrrd'\n",
        "methods = [\n",
        "    ('gaussian', {'sigma': 0.5}),\n",
        "    ('gamma_correction', {'gamma': 4}),\n",
        "    ('vesselness', {'sigma': 1.0, 'alpha': 0.5, 'beta': 0.5}),\n",
        "    ('sobel', {}),\n",
        "]\n",
        "\n",
        "process_volume_3d(input_volume_path, output_dir=output_dir, methods=methods)"
      ],
      "metadata": {
        "id": "1wuV8wp1yrpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5923d4cc-7b50-4b0e-d143-514611f173dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully read NRRD file: /content/Filtered_og_ctp.3D.nrrd\n",
            "Processing method: gaussian\n",
            "Applying gaussian filter with params: {'sigma': 0.5}\n",
            "gaussian filter applied and normalized successfully\n",
            "✅ Saved NRRD file to /content/drive/MyDrive/TFG 💪🧠/Code/DATA/P1/P1/Enhance_ctp_3D/Enhanced_gaussian_Filtered_og_ctp.3D.nrrd.nrrd\n",
            "Processing method: gamma_correction\n",
            "Applying gamma_correction filter with params: {'gamma': 4}\n",
            "Applying Gamma correction with gamma=4\n",
            "gamma_correction filter applied and normalized successfully\n",
            "✅ Saved NRRD file to /content/drive/MyDrive/TFG 💪🧠/Code/DATA/P1/P1/Enhance_ctp_3D/Enhanced_gamma_correction_Filtered_og_ctp.3D.nrrd.nrrd\n",
            "Processing method: vesselness\n",
            "Applying vesselness filter with params: {'sigma': 1.0, 'alpha': 0.5, 'beta': 0.5}\n",
            "Applying vesselness filter with sigma=1.0, alpha=0.5, beta=0.5\n",
            "vesselness filter applied and normalized successfully\n",
            "✅ Saved NRRD file to /content/drive/MyDrive/TFG 💪🧠/Code/DATA/P1/P1/Enhance_ctp_3D/Enhanced_vesselness_Filtered_og_ctp.3D.nrrd.nrrd\n",
            "Processing method: sobel\n",
            "Applying sobel filter with params: {}\n",
            "Applying Sobel edge detection filter\n",
            "sobel filter applied and normalized successfully\n",
            "✅ Saved NRRD file to /content/drive/MyDrive/TFG 💪🧠/Code/DATA/P1/P1/Enhance_ctp_3D/Enhanced_sobel_Filtered_og_ctp.3D.nrrd.nrrd\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gaussian': array([[[0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         ...,\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206]],\n",
              " \n",
              "        [[0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         ...,\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206]],\n",
              " \n",
              "        [[0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         ...,\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         ...,\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206]],\n",
              " \n",
              "        [[0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         ...,\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206]],\n",
              " \n",
              "        [[0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         ...,\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206],\n",
              "         [0.23917206, 0.23917206, 0.23917206, ..., 0.23917206,\n",
              "          0.23917206, 0.23917206]]], dtype=float32),\n",
              " 'gamma_correction': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32),\n",
              " 'vesselness': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " 'sobel': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labeling and centroides\n",
        "\n"
      ],
      "metadata": {
        "id": "y7edjxG9nfqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_shape_and_coordinates(volume, shape_type='sphere', threshold=0.5):\n",
        "    \"\"\"\n",
        "    Detects regions in a 3D volume based on their shape and returns their coordinates and centroids.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Step 1: Apply threshold to the volume\n",
        "        binary_volume = volume > threshold\n",
        "\n",
        "        # Step 2: Label the connected components in the binary volume\n",
        "        labeled_volume, num_labels = label(binary_volume)\n",
        "\n",
        "        # Step 3: Analyze each region (connected component)\n",
        "        shapes_data = []\n",
        "\n",
        "        for region in regionprops(labeled_volume):\n",
        "            # Calculate the centroid of the region\n",
        "            centroid = region.centroid\n",
        "\n",
        "            # Get the coordinates of the region\n",
        "            region_coords = region.coords\n",
        "\n",
        "            # Calculate the bounding box and aspect ratio (for shape detection)\n",
        "            minr, minc, minz, maxr, maxc, maxz = region.bbox\n",
        "            length = maxr - minr\n",
        "            width = maxc - minc\n",
        "            height = maxz - minz\n",
        "\n",
        "            # Aspect ratio for shape classification (simple criteria for shapes)\n",
        "            aspect_ratio = max(length, width, height) / min(length, width, height)\n",
        "\n",
        "            # Check shape types based on aspect ratio and volume\n",
        "            if shape_type == 'sphere':\n",
        "                # For spheres, aspect ratio should be close to 1\n",
        "                if 0.9 <= aspect_ratio <= 1.1:\n",
        "                    shapes_data.append({\n",
        "                        'type': 'sphere',\n",
        "                        'centroid': centroid,\n",
        "                        'coordinates': region_coords.tolist(),\n",
        "                        'volume': region.area\n",
        "                    })\n",
        "            elif shape_type == 'square':\n",
        "                # For squares (in 2D) or cubes in 3D, aspect ratio should be close to 1\n",
        "                if 0.9 <= aspect_ratio <= 1.1 and region.area > 100:  # Only considering large regions\n",
        "                    shapes_data.append({\n",
        "                        'type': 'square',\n",
        "                        'centroid': centroid,\n",
        "                        'coordinates': region_coords.tolist(),\n",
        "                        'volume': region.area\n",
        "                    })\n",
        "            elif shape_type == 'rectangle':\n",
        "                # For rectangles (or rectangular prisms in 3D), aspect ratio should be greater than 1\n",
        "                if aspect_ratio > 1.2:\n",
        "                    shapes_data.append({\n",
        "                        'type': 'rectangle',\n",
        "                        'centroid': centroid,\n",
        "                        'coordinates': region_coords.tolist(),\n",
        "                        'volume': region.area\n",
        "                    })\n",
        "\n",
        "        # Step 4: Convert results into a DataFrame for easy export\n",
        "        shapes_df = pd.DataFrame(shapes_data)\n",
        "        return shapes_df\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error detecting shapes: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Example usage\n",
        "volume = np.random.random((100, 100, 100))  # Replace with your 3D volume (e.g., from NRRD file)\n",
        "shapes_df = detect_shape_and_coordinates(volume, shape_type='sphere', threshold=0.5)\n",
        "\n",
        "if shapes_df is not None:\n",
        "    # Save to CSV or print the results\n",
        "    shapes_df.to_csv('shapes_data.csv', index=False)\n",
        "    print(shapes_df)"
      ],
      "metadata": {
        "id": "RpPxyuvBnimY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}