{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UNcFQ5xnDAx9V9l9mJPnY0EH2urRHmSF",
      "authorship_tag": "ABX9TyOJ0+90/53Xi838aFmSDQEH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rociavl/SEEG_automatic_segmentation/blob/main/3D_filters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3D Filters\n"
      ],
      "metadata": {
        "id": "E88kDUUBvvfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HCgnqeyMEk1",
        "outputId": "85e65a60-f867-4179-a099-60bf64591dd3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/MyDrive/TFG üí™üß†/Code/DATA/'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UFeFdfUMdW5",
        "outputId": "3d2a71be-bbff-497e-eb2c-0fe9d59d60f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P1  P2\tP3  P4\tP5  P6\tP7  P8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJg6Kz0hvm_i",
        "outputId": "0c149e2a-6fe4-4256-b640-bfcc84c712ad",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.3/52.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.4.1\n",
            "Collecting pynrrd\n",
            "  Downloading pynrrd-1.1.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from pynrrd) (1.26.4)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from pynrrd) (4.12.2)\n",
            "Downloading pynrrd-1.1.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pynrrd\n",
            "Successfully installed pynrrd-1.1.3\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install pynrrd\n",
        "!pip install scikit-image\n",
        "!pip install scipy\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.ndimage as ndi\n",
        "import SimpleITK as sitk  # For handling NRRD files\n",
        "from scipy.ndimage import gaussian_filter, median_filter, laplace, sobel\n",
        "import logging\n",
        "from skimage.filters import frangi\n",
        "from pathlib import Path\n",
        "import os\n",
        "from skimage.measure import regionprops\n",
        "import logging\n",
        "import nrrd\n",
        "from skimage.measure import label, regionprops\n",
        "from scipy.ndimage import gaussian_filter, median_filter, sobel\n",
        "from pathlib import Path\n",
        "import os\n",
        "from skimage.measure import label, regionprops\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import pandas as pd\n",
        "from scipy.ndimage import median_filter\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n"
      ],
      "metadata": {
        "id": "30i8daXAvzJe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_nrrd_file(file_path):\n",
        "    \"\"\"\n",
        "    Reads an NRRD file and returns the image as a numpy array and SimpleITK image.\n",
        "    Ensures the array values are scaled between 0 and 1, and checks that it's not RGB.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read the image\n",
        "        image = sitk.ReadImage(file_path)\n",
        "        image_array = sitk.GetArrayFromImage(image)  # Convert to numpy array\n",
        "\n",
        "        if len(image_array.shape) > 3:\n",
        "            # This could be a multi-channel volumetric image\n",
        "            channel_dim = -1  # Assume last dimension is channels\n",
        "            num_channels = image_array.shape[channel_dim]\n",
        "\n",
        "            if num_channels in [3, 4]:\n",
        "                logging.warning(f\"‚ö†Ô∏è Image appears to be RGB/RGBA with {num_channels} channels. Converting to grayscale.\")\n",
        "                image_array = np.mean(image_array, axis=channel_dim)\n",
        "\n",
        "        # Get original data range\n",
        "        orig_min = np.min(image_array)\n",
        "        orig_max = np.max(image_array)\n",
        "\n",
        "        # Normalize to 0-1 range if needed\n",
        "        if orig_min != 0 or orig_max != 1:\n",
        "            if orig_max > orig_min:  # Prevent division by zero\n",
        "                image_array = (image_array - orig_min) / (orig_max - orig_min)\n",
        "                logging.info(f\"‚úÖ Normalized image from range [{orig_min}, {orig_max}] to [0, 1]\")\n",
        "            else:\n",
        "                logging.warning(\"‚ö†Ô∏è Image has constant value. Setting to zeros.\")\n",
        "                image_array = np.zeros_like(image_array)\n",
        "\n",
        "        print(f\"‚úÖ Successfully read NRRD file: {file_path}\")\n",
        "        print(f\"   Shape: {image_array.shape}, Range: [{np.min(image_array)}, {np.max(image_array)}]\")\n",
        "\n",
        "        return image_array, image\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"‚ùå Error reading NRRD file: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def save_nrrd_file(image_array, image, output_file):\n",
        "    \"\"\"Saves a processed volume as an NRRD file using SimpleITK.\"\"\"\n",
        "    try:\n",
        "\n",
        "        if image_array.dtype == bool:\n",
        "            image_array = image_array.astype(np.uint8)\n",
        "\n",
        "        output_image = sitk.GetImageFromArray(image_array)\n",
        "        output_image.SetSpacing(image.GetSpacing())\n",
        "        output_image.SetOrigin(image.GetOrigin())\n",
        "\n",
        "        sitk.WriteImage(output_image, output_file)\n",
        "        print(f\"‚úÖ Saved NRRD file to {output_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"‚ùå Error saving NRRD file: {str(e)}\")"
      ],
      "metadata": {
        "id": "_WJR-V31xRTn"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resample_to_isotropic(image, spacing=(1.0, 1.0, 1.0)):\n",
        "    \"\"\"Resample image to isotropic spacing.\"\"\"\n",
        "    try:\n",
        "        # Get original image size and spacing\n",
        "        original_size = image.GetSize()\n",
        "        original_spacing = image.GetSpacing()\n",
        "\n",
        "        print(f\"Original size: {original_size}\")\n",
        "        print(f\"Original spacing: {original_spacing}\")\n",
        "        print(f\"Requested isotropic spacing: {spacing}\")\n",
        "\n",
        "        # Calculate the new size based on the original size and spacing\n",
        "        new_size = [\n",
        "            int(round(s * o / ns))\n",
        "            for s, o, ns in zip(original_size, original_spacing, spacing)\n",
        "        ]\n",
        "\n",
        "        print(f\"Calculated new size: {new_size}\")\n",
        "\n",
        "        resampler = sitk.ResampleImageFilter()\n",
        "        resampler.SetSize(new_size)\n",
        "        resampler.SetOutputSpacing(spacing)\n",
        "        resampler.SetInterpolator(sitk.sitkLinear)\n",
        "        resampler.SetOutputOrigin(image.GetOrigin())\n",
        "        resampler.SetOutputDirection(image.GetDirection())\n",
        "\n",
        "        resampled_image = resampler.Execute(image)\n",
        "\n",
        "        print(f\"Resampling successful. New size: {resampled_image.GetSize()}\")\n",
        "\n",
        "        return resampled_image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in resampling: {e}\")\n",
        "        return None\n",
        "\n",
        "def apply_brain_mask(image, brain_mask):\n",
        "    return sitk.Mask(image, brain_mask)\n",
        "\n",
        "def threshold_metal_voxels(image_array, percentile=99.5):\n",
        "    threshold_value = np.percentile(image_array, percentile)\n",
        "    return image_array > threshold_value\n",
        "\n",
        "def apply_median_filter(image_array, kernel_size=3):\n",
        "    return median_filter(image_array, size=kernel_size)\n",
        "\n",
        "def remove_large_objects(volume, size_threshold):\n",
        "    \"\"\"\n",
        "    Removes objects that are larger than a given size threshold. It's not working yet :C\n",
        "\n",
        "    Parameters:\n",
        "        volume (numpy.ndarray): The 3D image (volume).\n",
        "        size_threshold (int): The size threshold for removing large objects.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The volume with large objects removed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        labeled_volume, num_features = label(volume > 0)\n",
        "        regions = regionprops(labeled_volume)\n",
        "        filtered_volume = np.zeros_like(volume)\n",
        "\n",
        "        for region in regions:\n",
        "            if region.area <= size_threshold:\n",
        "                for coord in region.coords:\n",
        "                    filtered_volume[tuple(coord)] = volume[tuple(coord)]  # Keep small objects\n",
        "\n",
        "        print(f\"‚úÖ Removed {num_features - len([r for r in regions if r.area <= size_threshold])} large objects\")\n",
        "        return filtered_volume\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"‚ùå Error removing large objects: {str(e)}\")\n",
        "        return volume\n",
        "\n",
        "\n",
        "# Vesselness Filter (Custom Implementation)\n",
        "def vesselness_filter(image, sigma=1.0, alpha=0.5, beta=0.5):\n",
        "    \"\"\"\n",
        "    Applies custom vesselness filter for enhancing vessels.\n",
        "\n",
        "    Parameters:\n",
        "        image (numpy.ndarray): The 3D image (volume) to be filtered.\n",
        "        sigma (float): The standard deviation of the Gaussian filter used in Hessian computation.\n",
        "        alpha (float): The sensitivity parameter for vesselness calculation.\n",
        "        beta (float): The sensitivity parameter for vesselness calculation.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The vesselness-enhanced image.\n",
        "    \"\"\"\n",
        "    print(f\"Applying vesselness filter with sigma={sigma}, alpha={alpha}, beta={beta}\")\n",
        "    try:\n",
        "        # Compute second derivatives\n",
        "        Dxx = gaussian_filter(image, sigma=sigma, order=(2, 0, 0))\n",
        "        Dyy = gaussian_filter(image, sigma=sigma, order=(0, 2, 0))\n",
        "        Dzz = gaussian_filter(image, sigma=sigma, order=(0, 0, 2))\n",
        "        Dxy = gaussian_filter(image, sigma=sigma, order=(1, 1, 0))\n",
        "        Dxz = gaussian_filter(image, sigma=sigma, order=(1, 0, 1))\n",
        "        Dyz = gaussian_filter(image, sigma=sigma, order=(0, 1, 1))\n",
        "\n",
        "        # Initialize output\n",
        "        vesselness = np.zeros_like(image)\n",
        "\n",
        "        # Process each voxel\n",
        "        for i in range(image.shape[0]):\n",
        "            for j in range(image.shape[1]):\n",
        "                for k in range(image.shape[2]):\n",
        "                    # Construct Hessian matrix for this voxel\n",
        "                    H = np.array([\n",
        "                        [Dxx[i,j,k], Dxy[i,j,k], Dxz[i,j,k]],\n",
        "                        [Dxy[i,j,k], Dyy[i,j,k], Dyz[i,j,k]],\n",
        "                        [Dxz[i,j,k], Dyz[i,j,k], Dzz[i,j,k]]\n",
        "                    ])\n",
        "\n",
        "                    # Compute eigenvalues\n",
        "                    eigvals = np.linalg.eigvalsh(H)\n",
        "\n",
        "                    # Sort eigenvalues by absolute value (|Œª1| ‚â§ |Œª2| ‚â§ |Œª3|)\n",
        "                    eigvals = np.sort(np.abs(eigvals))\n",
        "\n",
        "                    # Compute vesselness - vessel structures have |Œª1| ‚âà 0, |Œª2| ‚âà |Œª3| >> 0\n",
        "                    if eigvals[1] > 0 and eigvals[2] > 0:  # Both Œª2 and Œª3 should be positive for vessel-like structures\n",
        "                        vessel_term = 1 - np.exp(-eigvals[1]**2 / (2 * alpha**2))\n",
        "                        blob_term = np.exp(-eigvals[2]**2 / (2 * beta**2))\n",
        "                        vesselness[i,j,k] = vessel_term * blob_term\n",
        "\n",
        "        # Normalize vesselness\n",
        "        if vesselness.max() > vesselness.min():\n",
        "            vesselness = (vesselness - vesselness.min()) / (vesselness.max() - vesselness.min())\n",
        "\n",
        "        return vesselness\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error applying vesselness filter: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Sobel filter for edge detection (CPU)\n",
        "def sobel_filter(image):\n",
        "    \"\"\"Applies Sobel edge detection filter on the CPU.\"\"\"\n",
        "    print(\"Applying Sobel edge detection filter\")\n",
        "    try:\n",
        "        edges = np.sqrt(sobel(image, axis=0)**2 + sobel(image, axis=1)**2 + sobel(image, axis=2)**2)\n",
        "        return edges\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error applying Sobel filter: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Gamma correction (CPU)\n",
        "def gamma_correction(image, gamma=1.0):\n",
        "    \"\"\"Applies Gamma correction to the image.\"\"\"\n",
        "    print(f\"Applying Gamma correction with gamma={gamma}\")\n",
        "    try:\n",
        "        image = np.power(image, gamma)\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error applying gamma correction: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def hessian_filter(image, sigma=1.0):\n",
        "    \"\"\"Apply Hessian-based filtering for blob detection.\"\"\"\n",
        "    print(f\"Applying Hessian filter with sigma={sigma}\")\n",
        "    try:\n",
        "        # Compute the Hessian matrix at each voxel\n",
        "        Dxx = gaussian_filter(image, sigma=sigma, order=(2, 0, 0))\n",
        "        Dyy = gaussian_filter(image, sigma=sigma, order=(0, 2, 0))\n",
        "        Dzz = gaussian_filter(image, sigma=sigma, order=(0, 0, 2))\n",
        "        Dxy = gaussian_filter(image, sigma=sigma, order=(1, 1, 0))\n",
        "        Dxz = gaussian_filter(image, sigma=sigma, order=(1, 0, 1))\n",
        "        Dyz = gaussian_filter(image, sigma=sigma, order=(0, 1, 1))\n",
        "\n",
        "        result = np.zeros_like(image)\n",
        "\n",
        "        # Process each voxel\n",
        "        for i in range(image.shape[0]):\n",
        "            for j in range(image.shape[1]):\n",
        "                for k in range(image.shape[2]):\n",
        "                    # Construct Hessian matrix for this voxel\n",
        "                    H = np.array([\n",
        "                        [Dxx[i,j,k], Dxy[i,j,k], Dxz[i,j,k]],\n",
        "                        [Dxy[i,j,k], Dyy[i,j,k], Dyz[i,j,k]],\n",
        "                        [Dxz[i,j,k], Dyz[i,j,k], Dzz[i,j,k]]\n",
        "                    ])\n",
        "\n",
        "                    # Compute eigenvalues\n",
        "                    eigvals = np.linalg.eigvalsh(H)\n",
        "\n",
        "                    # Blobs have all eigenvalues with same sign and similar magnitude\n",
        "                    # Store product of eigenvalues (determinant) as blob measure\n",
        "                    result[i,j,k] = np.prod(eigvals)\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error applying Hessian filter: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def anisotropic_diffusion(image, num_iter=10, kappa=50, gamma=0.1):\n",
        "    \"\"\"Apply Anisotropic Diffusion (Perona-Malik) on a 3D image (volume).\"\"\"\n",
        "    image = np.asarray(image, dtype=np.float64)\n",
        "\n",
        "    print(\"Input image shape before anisotropic diffusion:\", image.shape)\n",
        "\n",
        "    # Assuming 3D image with shape [z, y, x]\n",
        "    for iteration in range(num_iter):\n",
        "        print(f\"Iteration {iteration + 1}/{num_iter}\")\n",
        "\n",
        "        # Calculate gradients along each spatial axis\n",
        "        # For X axis (axis=2)\n",
        "        diff_x = np.zeros_like(image)\n",
        "        diff_x[:, :, 1:] = image[:, :, 1:] - image[:, :, :-1]  # Forward difference\n",
        "\n",
        "        # For Y axis (axis=1)\n",
        "        diff_y = np.zeros_like(image)\n",
        "        diff_y[:, 1:, :] = image[:, 1:, :] - image[:, :-1, :]\n",
        "\n",
        "        # For Z axis (axis=0)\n",
        "        diff_z = np.zeros_like(image)\n",
        "        diff_z[1:, :, :] = image[1:, :, :] - image[:-1, :, :]\n",
        "\n",
        "        # Compute diffusion coefficients\n",
        "        c_x = np.exp(-(diff_x / kappa) ** 2)\n",
        "        c_y = np.exp(-(diff_y / kappa) ** 2)\n",
        "        c_z = np.exp(-(diff_z / kappa) ** 2)\n",
        "\n",
        "        # Compute flux terms\n",
        "        flux_x = c_x * diff_x\n",
        "        flux_y = c_y * diff_y\n",
        "        flux_z = c_z * diff_z\n",
        "\n",
        "        # Compute divergence (update step)\n",
        "        div_x = np.zeros_like(image)\n",
        "        div_x[:, :, :-1] += flux_x[:, :, :-1]\n",
        "        div_x[:, :, 1:] -= flux_x[:, :, :-1]\n",
        "\n",
        "        div_y = np.zeros_like(image)\n",
        "        div_y[:, :-1, :] += flux_y[:, :-1, :]\n",
        "        div_y[:, 1:, :] -= flux_y[:, :-1, :]\n",
        "\n",
        "        div_z = np.zeros_like(image)\n",
        "        div_z[:-1, :, :] += flux_z[:-1, :, :]\n",
        "        div_z[1:, :, :] -= flux_z[:-1, :, :]\n",
        "\n",
        "        # Update image\n",
        "        image += gamma * (div_x + div_y + div_z)\n",
        "\n",
        "        print(f\"Image shape after iteration {iteration + 1}: {image.shape}\")\n",
        "        print(f\"Min value after iteration {iteration + 1}: {np.min(image)}\")\n",
        "        print(f\"Max value after iteration {iteration + 1}: {np.max(image)}\")\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "4xEASN5GIidu"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process volume with cascading filters using CPU"
      ],
      "metadata": {
        "id": "1wctH5k_In0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_volume_3d(input_volume_path, output_dir=None, filename_pattern=\"Enhanced_{name}_{original}.nrrd\"):\n",
        "    \"\"\"Processes the volume with multiple filters in sequence.\"\"\"\n",
        "    try:\n",
        "        # Load the input volume\n",
        "        image_array, image = read_nrrd_file(input_volume_path)\n",
        "\n",
        "        if image_array is None or image is None:\n",
        "            print(\"‚ùå Failed to load input volume.\")\n",
        "            return\n",
        "\n",
        "        # Apply filters in sequence (cascade-like processing)\n",
        "        enhanced_volumes = {}\n",
        "\n",
        "        # Apply filters in sequence\n",
        "        enhanced_volumes['thresholding_percentile'] = threshold_metal_voxels(image_array, percentile=99.5)\n",
        "        enhanced_volumes['gamma_2'] = gamma_correction(enhanced_volumes['thresholding_percentile'], gamma=2)\n",
        "        enhanced_volumes['gamma_4'] = gamma_correction(enhanced_volumes['gamma_2'], gamma=4)\n",
        "        enhanced_volumes['hessian'] = hessian_filter(enhanced_volumes['gamma_4'], sigma=1)\n",
        "        enhanced_volumes['anisotropic'] = anisotropic_diffusion(enhanced_volumes['hessian'], num_iter=10, kappa=50, gamma=0.1)\n",
        "        enhanced_volumes['sobel'] = sobel_filter(enhanced_volumes['anisotropic'])\n",
        "\n",
        "        # Save the processed volumes in the output directory\n",
        "        if output_dir:\n",
        "            output_path = Path(output_dir)\n",
        "            output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            # Save each enhanced volume with the custom filename pattern\n",
        "            for name, volume in enhanced_volumes.items():\n",
        "                filename = filename_pattern.format(name=name, original=os.path.basename(input_volume_path))\n",
        "                output_file = output_path / filename\n",
        "                save_nrrd_file(volume, image, str(output_file))\n",
        "\n",
        "        return enhanced_volumes\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during volume processing: {str(e)}\")"
      ],
      "metadata": {
        "id": "9Piy2saav4SE"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/TFG üí™üß†/Code/DATA/P1/P1/Enhance_ctp_3D'\n",
        "output_path = Path(output_dir)\n",
        "output_path.mkdir(parents=True, exist_ok=True) 
        "if output_path.exists():\n",
        "    print(f\"‚úÖ Output directory exists or was created: {output_dir}\")\n",
        "else:\n",
        "    print(f\"‚ùå Failed to create output directory: {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33t0faAHJ87e",
        "outputId": "2b5052bc-239a-46d7-ed25-58effd26bf72"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Output directory exists or was created: /content/drive/MyDrive/TFG üí™üß†/Code/DATA/P1/P1/Enhance_ctp_3D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "input_volume_path ='/content/Filtered_og_ctp.3D.nrrd'\n",
        "\n",
        "process_volume_3d(input_volume_path, output_dir=output_dir,filename_pattern=\"Filtered_{name}_{original}.nrrd\")"
      ],
      "metadata": {
        "id": "1wuV8wp1yrpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ddd91a5-a464-463e-a79e-446c8083570b"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Successfully read NRRD file: /content/Filtered_og_ctp.3D.nrrd\n",
            "   Shape: (256, 256, 256), Range: [0.0, 1.0]\n",
            "Applying Gamma correction with gamma=2\n",
            "Applying Gamma correction with gamma=4\n",
            "Applying Hessian filter with sigma=1\n",
            "Input image shape before anisotropic diffusion: (256, 256, 256)\n",
            "Iteration 1/10\n",
            "Image shape after iteration 1: (256, 256, 256)\n",
            "Min value after iteration 1: 0.0\n",
            "Max value after iteration 1: 0.0\n",
            "Iteration 2/10\n",
            "Image shape after iteration 2: (256, 256, 256)\n",
            "Min value after iteration 2: 0.0\n",
            "Max value after iteration 2: 0.0\n",
            "Iteration 3/10\n",
            "Image shape after iteration 3: (256, 256, 256)\n",
            "Min value after iteration 3: 0.0\n",
            "Max value after iteration 3: 0.0\n",
            "Iteration 4/10\n",
            "Image shape after iteration 4: (256, 256, 256)\n",
            "Min value after iteration 4: 0.0\n",
            "Max value after iteration 4: 0.0\n",
            "Iteration 5/10\n",
            "Image shape after iteration 5: (256, 256, 256)\n",
            "Min value after iteration 5: 0.0\n",
            "Max value after iteration 5: 0.0\n",
            "Iteration 6/10\n",
            "Image shape after iteration 6: (256, 256, 256)\n",
            "Min value after iteration 6: 0.0\n",
            "Max value after iteration 6: 0.0\n",
            "Iteration 7/10\n",
            "Image shape after iteration 7: (256, 256, 256)\n",
            "Min value after iteration 7: 0.0\n",
            "Max value after iteration 7: 0.0\n",
            "Iteration 8/10\n",
            "Image shape after iteration 8: (256, 256, 256)\n",
            "Min value after iteration 8: 0.0\n",
            "Max value after iteration 8: 0.0\n",
            "Iteration 9/10\n",
            "Image shape after iteration 9: (256, 256, 256)\n",
            "Min value after iteration 9: 0.0\n",
            "Max value after iteration 9: 0.0\n",
            "Iteration 10/10\n",
            "Image shape after iteration 10: (256, 256, 256)\n",
            "Min value after iteration 10: 0.0\n",
            "Max value after iteration 10: 0.0\n",
            "Applying Sobel edge detection filter\n",
            "‚úÖ Saved NRRD file to /content/drive/MyDrive/TFG üí™üß†/Code/DATA/P1/P1/Enhance_ctp_3D/Filtered_thresholding_percentile_Filtered_og_ctp.3D.nrrd.nrrd\n",
            "‚úÖ Saved NRRD file to /content/drive/MyDrive/TFG üí™üß†/Code/DATA/P1/P1/Enhance_ctp_3D/Filtered_gamma_2_Filtered_og_ctp.3D.nrrd.nrrd\n",
            "‚úÖ Saved NRRD file to /content/drive/MyDrive/TFG üí™üß†/Code/DATA/P1/P1/Enhance_ctp_3D/Filtered_gamma_4_Filtered_og_ctp.3D.nrrd.nrrd\n",
            "‚úÖ Saved NRRD file to /content/drive/MyDrive/TFG üí™üß†/Code/DATA/P1/P1/Enhance_ctp_3D/Filtered_hessian_Filtered_og_ctp.3D.nrrd.nrrd\n",
            "‚úÖ Saved NRRD file to /content/drive/MyDrive/TFG üí™üß†/Code/DATA/P1/P1/Enhance_ctp_3D/Filtered_anisotropic_Filtered_og_ctp.3D.nrrd.nrrd\n",
            "‚úÖ Saved NRRD file to /content/drive/MyDrive/TFG üí™üß†/Code/DATA/P1/P1/Enhance_ctp_3D/Filtered_sobel_Filtered_og_ctp.3D.nrrd.nrrd\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'thresholding_percentile': array([[[False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         ...,\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False]],\n",
              " \n",
              "        [[False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         ...,\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False]],\n",
              " \n",
              "        [[False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         ...,\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         ...,\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False]],\n",
              " \n",
              "        [[False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         ...,\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False]],\n",
              " \n",
              "        [[False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         ...,\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False],\n",
              "         [False, False, False, ..., False, False, False]]]),\n",
              " 'gamma_2': array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]]]),\n",
              " 'gamma_4': array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]]]),\n",
              " 'hessian': array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]]]),\n",
              " 'anisotropic': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]]),\n",
              " 'sobel': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]])}"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labeling and centroides\n",
        "\n"
      ],
      "metadata": {
        "id": "y7edjxG9nfqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_shape_and_coordinates(volume, shape_type='sphere', threshold=0.5):\n",
        "    \"\"\"\n",
        "    Detects regions in a 3D volume based on their shape and returns their coordinates and centroids.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Step 1: Apply threshold to the volume\n",
        "        binary_volume = volume > threshold\n",
        "\n",
        "        # Step 2: Label the connected components in the binary volume\n",
        "        labeled_volume, num_labels = label(binary_volume)\n",
        "\n",
        "        # Step 3: Analyze each region (connected component)\n",
        "        shapes_data = []\n",
        "\n",
        "        for region in regionprops(labeled_volume):\n",
        "            # Calculate the centroid of the region\n",
        "            centroid = region.centroid\n",
        "\n",
        "            # Get the coordinates of the region\n",
        "            region_coords = region.coords\n",
        "\n",
        "            # Calculate the bounding box and aspect ratio (for shape detection)\n",
        "            minr, minc, minz, maxr, maxc, maxz = region.bbox\n",
        "            length = maxr - minr\n",
        "            width = maxc - minc\n",
        "            height = maxz - minz\n",
        "\n",
        "            # Aspect ratio for shape classification (simple criteria for shapes)\n",
        "            aspect_ratio = max(length, width, height) / min(length, width, height)\n",
        "\n",
        "            # Check shape types based on aspect ratio and volume\n",
        "            if shape_type == 'sphere':\n",
        "                # For spheres, aspect ratio should be close to 1\n",
        "                if 0.9 <= aspect_ratio <= 1.1:\n",
        "                    shapes_data.append({\n",
        "                        'type': 'sphere',\n",
        "                        'centroid': centroid,\n",
        "                        'coordinates': region_coords.tolist(),\n",
        "                        'volume': region.area\n",
        "                    })\n",
        "            elif shape_type == 'square':\n",
        "                # For squares (in 2D) or cubes in 3D, aspect ratio should be close to 1\n",
        "                if 0.9 <= aspect_ratio <= 1.1 and region.area > 100:  # Only considering large regions\n",
        "                    shapes_data.append({\n",
        "                        'type': 'square',\n",
        "                        'centroid': centroid,\n",
        "                        'coordinates': region_coords.tolist(),\n",
        "                        'volume': region.area\n",
        "                    })\n",
        "            elif shape_type == 'rectangle':\n",
        "                # For rectangles (or rectangular prisms in 3D), aspect ratio should be greater than 1\n",
        "                if aspect_ratio > 1.2:\n",
        "                    shapes_data.append({\n",
        "                        'type': 'rectangle',\n",
        "                        'centroid': centroid,\n",
        "                        'coordinates': region_coords.tolist(),\n",
        "                        'volume': region.area\n",
        "                    })\n",
        "\n",
        "        # Step 4: Convert results into a DataFrame for easy export\n",
        "        shapes_df = pd.DataFrame(shapes_data)\n",
        "        return shapes_df\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error detecting shapes: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Example usage\n",
        "volume = np.random.random((100, 100, 100))  # Replace with your 3D volume (e.g., from NRRD file)\n",
        "shapes_df = detect_shape_and_coordinates(volume, shape_type='sphere', threshold=0.5)\n",
        "\n",
        "if shapes_df is not None:\n",
        "    # Save to CSV or print the results\n",
        "    shapes_df.to_csv('shapes_data.csv', index=False)\n",
        "    print(shapes_df)"
      ],
      "metadata": {
        "id": "RpPxyuvBnimY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
